### 7. TensorFlow.js

#### 7.2. 고급 TensorFlow.js

##### 7.2.3. 자연어 처리 모델

자연어 처리(NLP)는 텍스트 데이터를 분석하고 이해하는 기술입니다. TensorFlow.js를 사용하여 간단한 자연어 처리 모델을 구축하고 훈련하는 방법을 설명하겠습니다. 여기서는 LSTM(Long Short-Term Memory) 네트워크를 사용하여 텍스트 분류 모델을 만드는 예제를 다룹니다.

###### 데이터 전처리

1. **텍스트 데이터 토큰화**

   텍스트 데이터를 숫자 인덱스로 변환합니다.

   ```javascript
   const tokenizer = new tf.keras.preprocessing.text.Tokenizer();
   const texts = [
     'TensorFlow.js is great',
     'I love machine learning',
     'JavaScript is awesome'
   ];
   tokenizer.fitOnTexts(texts);
   const sequences = tokenizer.textsToSequences(texts);
   console.log(sequences);
   ```

2. **패딩**

   시퀀스의 길이를 동일하게 맞추기 위해 패딩을 추가합니다.

   ```javascript
   const paddedSequences = tf.keras.preprocessing.sequence.padSequences(sequences, { padding: 'post' });
   console.log(paddedSequences);
   ```

###### 모델 정의

1. **LSTM 모델 정의**

   LSTM 네트워크를 사용하여 텍스트 분류 모델을 정의합니다.

   ```javascript
   const model = tf.sequential();
   model.add(tf.layers.embedding({ inputDim: tokenizer.wordIndex.length + 1, outputDim: 16, inputLength: paddedSequences[0].length }));
   model.add(tf.layers.lstm({ units: 32 }));
   model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));
   ```

###### 모델 컴파일 및 훈련

1. **모델 컴파일**

   모델을 컴파일합니다.

   ```javascript
   model.compile({
     optimizer: 'adam',
     loss: 'binaryCrossentropy',
     metrics: ['accuracy']
   });
   ```

2. **모델 훈련**

   예시 데이터를 사용하여 모델을 훈련합니다.

   ```javascript
   const labels = tf.tensor1d([1, 0, 1]); // 예시 레이블
   model.fit(tf.tensor2d(paddedSequences), labels, {
     epochs: 10,
     callbacks: {
       onEpochEnd: (epoch, logs) => {
         console.log(`Epoch ${epoch}: loss = ${logs.loss}`);
       }
     }
   });
   ```

###### 전체 예제

1. **자연어 처리 모델 전체 예제**

   ```html
   <!DOCTYPE html>
   <html lang="en">
   <head>
     <meta charset="UTF-8">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <title>TensorFlow.js NLP Example</title>
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
   </head>
   <body>
     <script>
       async function run() {
         const tokenizer = new tf.keras.preprocessing.text.Tokenizer();
         const texts = [
           'TensorFlow.js is great',
           'I love machine learning',
           'JavaScript is awesome'
         ];
         tokenizer.fitOnTexts(texts);
         const sequences = tokenizer.textsToSequences(texts);
         const paddedSequences = tf.keras.preprocessing.sequence.padSequences(sequences, { padding: 'post' });

         const model = tf.sequential();
         model.add(tf.layers.embedding({ inputDim: tokenizer.wordIndex.length + 1, outputDim: 16, inputLength: paddedSequences[0].length }));
         model.add(tf.layers.lstm({ units: 32 }));
         model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

         model.compile({
           optimizer: 'adam',
           loss: 'binaryCrossentropy',
           metrics: ['accuracy']
         });

         const labels = tf.tensor1d([1, 0, 1]); // 예시 레이블
         await model.fit(tf.tensor2d(paddedSequences), labels, {
           epochs: 10,
           callbacks: {
             onEpochEnd: (epoch, logs) => {
               console.log(`Epoch ${epoch}: loss = ${logs.loss}`);
             }
           }
         });
       }

       run();
     </script>
   </body>
   </html>
   ```

##### 연습문제와 해답

1. **TensorFlow.js를 사용하여 간단한 LSTM 텍스트 분류 모델을 정의하고 훈련하세요.**

   ```html
   <!DOCTYPE html>
   <html lang="en">
   <head>
     <meta charset="UTF-8">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <title>TensorFlow.js LSTM Text Classification Example</title>
     <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
   </head>
   <body>
     <script>
       async function run() {
         const tokenizer = new tf.keras.preprocessing.text.Tokenizer();
         const texts = [
           'TensorFlow.js is great',
           'I love machine learning',
           'JavaScript is awesome'
         ];
         tokenizer.fitOnTexts(texts);
         const sequences = tokenizer.textsToSequences(texts);
         const paddedSequences = tf.keras.preprocessing.sequence.padSequences(sequences, { padding: 'post' });

         const model = tf.sequential();
         model.add(tf.layers.embedding({ inputDim: tokenizer.wordIndex.length + 1, outputDim: 16, inputLength: paddedSequences[0].length }));
         model.add(tf.layers.lstm({ units: 32 }));
         model.add(tf.layers.dense({ units: 1, activation: 'sigmoid' }));

         model.compile({
           optimizer: 'adam',
           loss: 'binaryCrossentropy',
           metrics: ['accuracy']
         });

         const labels = tf.tensor1d([1, 0, 1]); // 예시 레이블
         await model.fit(tf.tensor2d(paddedSequences), labels, {
           epochs: 10,
           callbacks: {
             onEpochEnd: (epoch, logs) => {
               console.log(`Epoch ${epoch}: loss = ${logs.loss}`);
             }
           }
         });
       }

       run();
     </script>
   </body>
   </html>
   ```
